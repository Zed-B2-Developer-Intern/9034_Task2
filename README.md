# ğŸ§  Ollama Local AI Setup (Task 2)

This folder contains screenshots and notes related to setting up and running **Ollama** locally using Python and Postman.

## âœ… Task Completed

* Installed and configured Ollama on Windows
* Pulled and tested `llama3.2:1b` model
* Used Python to send prompts to Ollama via API
* Used Postman to test the API with JSON payload
* Verified offline capability after model download
* Uploaded screenshots to GitHub
* Created Python chatbot script (`ollama.py`)

## ğŸ› ï¸ Installation & Setup

### ğŸ§° 1. Install Ollama

Download and install from the official site:
ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

Once installed, verify using:

```bash
ollama --version
```

### ğŸ“¥ 2. Pull a Model

Use the following command to pull a small model:

```bash
ollama pull llama3.2:1b
```

You only need to do this **once** (models are saved locally).

### ğŸš€ 3. Start the Ollama Server

```bash
ollama serve
```

This runs the API on `http://localhost:11434`

### ğŸ§ª 4. Test with Python or Postman

Use either the provided `ollama.py` script or Postman to interact with the local model.

---

## ğŸ“¸ Screenshots

This folder includes:

* âœ… Ollama serve running
* âœ… Python chatbot working
* âœ… Postman request and response
* âœ… Model pull and storage confirmation

## ğŸ›  Technologies Used

* ğŸ Python 3.11
* ğŸ‹ Ollama (offline LLM serving)
* ğŸ§ª Postman for API testing
* ğŸ–¥ï¸ Windows 11

## ğŸ“‚ Directory

```
ollama/
   ollama.py
â””â”€â”€ screenshot/
    â”œâ”€â”€ serve_running.png
    â”œâ”€â”€ postman_test.png
    â”œâ”€â”€ python_chat.png
    â””â”€â”€ model_pull.png
```

## ğŸš€ How to Run Locally

1. Start Ollama server:

   ```bash
   ollama serve
   ```

2. Pull a model:

   ```bash
   ollama pull llama3.2:1b
   ```

3. Run Python chatbot script:

   ```bash
   python ollama.py
   ```

4. Or test with Postman at:

   ```
   http://localhost:11434/api/generate
   ```

## ğŸ¬ Video Demo

Watch the complete demo here: [ğŸ”— Click to Watch](https://www.example.com/ollama-demo) 

---

Feel free to explore and contribute!
